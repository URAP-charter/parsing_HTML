{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas\n",
    "import urllib, requests\n",
    "from requests.auth import HTTPBasicAuth, HTTPDigestAuth\n",
    "import re\n",
    "# import nbimporter #need to pip install this\n",
    "# import EncapsulatedSchoolObject as school"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Keyword lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#mission = [' vision ', 'Vision ', 'our purpose', ' cause ', ' objectives ', ' mission', ' vision: ', ' mission: ', 'Mission']\n",
    "#curriculum = [ 'program', 'methods', 'pedagogy', 'approach', 'model', 'curriculum', 'academics', 'degree']\n",
    "#philosophy = ['beliefs', 'principles', 'creed', 'Values', 'philosophy', 'moral']\n",
    "#history = ['story', 'background', 'founded', 'established']\n",
    "#target = ['gifted', 'at-risk', 'ethnic background', 'target population', 'target audience']\n",
    "#resources = ['ESL', 'tutoring', 'after-school programs', 'available resources', 'services', 'opportunities', 'opportunity']\n",
    "#orgfactor = ['statistics', 'API', 'environment', 'ratio', 'average', 'female', 'fund', 'community']\n",
    "\n",
    "mission = ['mission',' vision ', 'vision:', 'mission:', 'our purpose', 'our ideals', 'ideals:', 'our cause', 'cause:', 'goals', 'objective']\n",
    "curriculum = ['curriculum', 'curricular', 'program', 'method', 'pedagogy', 'pedagogical', 'approach', 'model', 'system', 'structure']\n",
    "philosophy = ['philosophy', 'philosophical', 'beliefs', 'believe', 'principles', 'creed', 'credo', 'value',  'moral', 'Values']\n",
    "history = ['history', 'our story', 'the story', 'school story', 'background', 'founding', 'founded', 'established', 'establishment', 'our school began', 'we began', 'doors opened', 'school opened']\n",
    "general =  ['about us', 'our school', 'who we are', 'overview', 'general information', 'our identity', 'profile', 'highlights']\n",
    "\n",
    "keyValues = [mission, curriculum, philosophy, history, general]\n",
    "nodeParams = ['mission', 'curriculum', 'philosophy', 'history', 'general']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "df = pandas.read_excel('micro-sample_MANUAL_Apr17_rev3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get the values from the URL column (stored as list)\n",
    "links = df['URL'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.richland2.org/charterhigh/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input test URL\n",
    "url = links[0]\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create HTML soup\n",
    "html_page = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(html_page, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BETA/ FOR REFERENCE (mostly from this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AKCAN'S VERSION:\n",
    "html_page = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(html_page, \"lxml\")\n",
    "\n",
    "# THAO'S VERSION:\n",
    "html_page = requests.get(url, auth=HTTPDigestAuth('user', 'pass'), headers= {'User-Agent':\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"})\n",
    "soup = BeautifulSoup(html_page.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'school' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-036d8ea104a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[1;31m#for i in range(5, 6):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[1;31m#testedLinks[links[i]] = school.WebsiteData(links[i], nodeParams, keyValues).createJsonNode()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtester\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyValues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodeParams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-036d8ea104a4>\u001b[0m in \u001b[0;36mtester\u001b[0;34m(links, keyValues, nodeParams)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtester\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyValues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodeParams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtestedLinks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mschool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWebsiteData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodeParams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyValues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateJsonNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[1;31m#for i in range(5, 6):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[1;31m#testedLinks[links[i]] = school.WebsiteData(links[i], nodeParams, keyValues).createJsonNode()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'school' is not defined"
     ]
    }
   ],
   "source": [
    "#(self, url, nodeParams, keyValues)\n",
    "\n",
    "\n",
    "#creating a list of all the keyword lists\n",
    "#keyValues = [mission, curriculum, philosophy, history, target, resources, orgfactor]\n",
    "keyValues = [mission, curriculum, philosophy, history, general]\n",
    "\n",
    "#creating a list of key names for the JSON node that correspond to the keyValues list\n",
    "#nodeParams = ['mission', 'curriculum', 'philosophy', 'history', 'target', 'resources' , 'organizational_factors']\n",
    "nodeParams = ['mission', 'curriculum', 'philosophy', 'history', 'general']\n",
    "testedLinks = {}\n",
    "\n",
    "#print(links[0])\n",
    "\n",
    "\n",
    "\n",
    "#constructor = school.WebsiteData('https://www.richland2.org/charterhigh/', nodeParams, keyValues)\n",
    "#constructor.createJsonNode()\n",
    "#print(constructor.URL)\n",
    "\n",
    "def tester(links, keyValues, nodeParams):\n",
    "    testedLinks[links[5]] = school.WebsiteData(links[5], nodeParams, keyValues).createJsonNode()\n",
    "    #for i in range(5, 6):\n",
    "        #testedLinks[links[i]] = school.WebsiteData(links[i], nodeParams, keyValues).createJsonNode()\n",
    "tester(links, keyValues, nodeParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING (from EncapsulatedSchoolObject.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finds all tags within a BeautifulSoup object that's text contains a certain keyword and returns a list of these tags.\n",
    "def findTags(soup, keyWord):\n",
    "    tagList = []\n",
    "        \n",
    "    for elem in soup(text=re.compile(keyWord)):\n",
    "        tagList.append(elem.parent)\n",
    "            \n",
    "    return tagList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Utilizes a BeautifulSoup object (soup) to scrape all text that contains the given keyword. Filters for certain tags and does\n",
    "#not take text from solely header (h) tags, instead takes text from next filtered tag after the header.  \n",
    "def keyWordScraper(soup, keyWord):\n",
    "    searchTxt = ''\n",
    "    correctName = ['p', 'li', 'table', 'ul', 'ol']\n",
    "    tagList = findTags(soup, keyWord)\n",
    "    #print(tagList)\n",
    "    \n",
    "    #This loop goes through each tag and rips the text from that tag. If that tag is a header, then the text from the next \n",
    "    #useful tag is ripped instead. All text is saved in searchTxt\n",
    "    for tag in tagList:\n",
    "        #print(tag, \"\\n\")\n",
    "        if 'h' in tag.name:\n",
    "            typeTag = type(soup.find('li'))\n",
    "            current = tag.next_sibling\n",
    "            while current != None and  not isinstance(current, typeTag) and current.name not in correctName:\n",
    "                current = current.next_sibling\n",
    "            if current != None:\n",
    "                if 'ul' in current.name or 'ol' in current.name:\n",
    "                    for li in current.findAll('li'):\n",
    "                        searchTxt = searchTxt + li.text\n",
    "                else:\n",
    "                    searchTxt = searchTxt + current.text\n",
    "        #elif url extension includes the keyWord, grab all the text?\n",
    "        else:\n",
    "            if(tag.name in correctName):\n",
    "                    searchTxt = searchTxt + tag.text\n",
    "                \n",
    "        return searchTxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Applies the keyWordScraper function to a BeautifulSoup object(soup) for a list of keywords. Returns the text found.\n",
    "def mapKeywordScraper(soup, keyWords):\n",
    "    foundTxt = ''\n",
    "    \n",
    "    for keyWord in keyWords:\n",
    "        foundTxt = foundTxt + str(keyWordScraper(soup, keyWord))\n",
    "    #print(foundTxt)\n",
    "    return foundTxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createJsonNode():\n",
    "    JSONNode = {}\n",
    "    \n",
    "    for x in range(0, len(keyValues)):\n",
    "        print(keyValues[x], \"\\n\")\n",
    "        JSONNode[nodeParams[x]] = [mapKeywordScraper(soup, keyValues[x])]\n",
    "        print(JSONNode)\n",
    "    return JSONNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mission', ' vision ', 'vision:', 'mission:', 'our purpose', 'our ideals', 'ideals:', 'our cause', 'cause:', 'goals', 'objective'] \n",
      "\n",
      "NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNone\n",
      "{'mission': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNone']}\n",
      "['curriculum', 'curricular', 'program', 'method', 'pedagogy', 'pedagogical', 'approach', 'model', 'system', 'structure'] \n",
      "\n",
      "NoneNoneNoneNoneNoneNoneNoneNoneNoneNone\n",
      "{'mission': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNone'], 'curriculum': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNone']}\n",
      "['philosophy', 'philosophical', 'beliefs', 'believe', 'principles', 'creed', 'credo', 'value', 'moral', 'Values'] \n",
      "\n",
      "NoneNoneNoneNoneNoneNoneNoneNoneNone\n",
      "{'mission': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNone'], 'curriculum': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNone'], 'philosophy': ['NoneNoneNoneNoneNoneNoneNoneNoneNone']}\n",
      "['history', 'our story', 'the story', 'school story', 'background', 'founding', 'founded', 'established', 'establishment', 'our school began', 'we began', 'doors opened', 'school opened'] \n",
      "\n",
      "NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNone\n",
      "{'mission': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNone'], 'curriculum': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNone'], 'philosophy': ['NoneNoneNoneNoneNoneNoneNoneNoneNone'], 'history': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNone']}\n",
      "['about us', 'our school', 'who we are', 'overview', 'general information', 'our identity', 'profile', 'highlights'] \n",
      "\n",
      "NoneNoneNoneNoneNoneNoneNoneNone\n",
      "{'mission': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNone'], 'curriculum': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNone'], 'philosophy': ['NoneNoneNoneNoneNoneNoneNoneNoneNone'], 'history': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNone'], 'general': ['NoneNoneNoneNoneNoneNoneNoneNone']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'curriculum': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNone'],\n",
       " 'general': ['NoneNoneNoneNoneNoneNoneNoneNone'],\n",
       " 'history': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNone'],\n",
       " 'mission': ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNone'],\n",
       " 'philosophy': ['NoneNoneNoneNoneNoneNoneNoneNoneNone']}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createJsonNode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CHUNKS OF CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.richland2.org/charterhigh/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input test URL here\n",
    "url = links[0]\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html_page = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(html_page, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findTags(soup, keyWord):\n",
    "    tagList = []\n",
    "        \n",
    "    for elem in soup(text=re.compile(keyWord)):\n",
    "        tagList.append(elem.parent)\n",
    "            \n",
    "    return tagList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1f8966b3d18d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtagList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindTags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyValues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-f7b26a6cb648>\u001b[0m in \u001b[0;36mfindTags\u001b[0;34m(soup, keyWord)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtagList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyWord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtagList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[1;34m\"Compile a regular expression pattern, returning a pattern object.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[1;31m# internal: compile pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_locale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetlocale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_locale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLC_CTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "tagList = findTags(soup, keyWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchTxt = ''\n",
    "correctName = ['p', 'li', 'table', 'ul', 'ol']\n",
    "tagList = findTags(soup, keyWord)\n",
    "    \n",
    "#This loop goes through each tag and rips the text from that tag. If that tag is a header, then the text from the next \n",
    " #useful tag is ripped instead. All text is saved in searchTxt\n",
    "for tag in tagList:\n",
    "    if 'h' in tag.name:\n",
    "        typeTag = type(soup.find('li'))\n",
    "        current = tag.next_sibling\n",
    "        while current != None and  not isinstance(current, typeTag) and current.name not in correctName:\n",
    "            current = current.next_sibling\n",
    "        if current != None:\n",
    "            if 'ul' in current.name or 'ol' in current.name:\n",
    "                for li in current.findAll('li'):\n",
    "                    searchTxt = searchTxt + li.text\n",
    "            else:\n",
    "                searchTxt = searchTxt + current.text\n",
    "    #elif url extension includes the keyWord, grab all the text?\n",
    "    else:\n",
    "        if(tag.name in correctName):\n",
    "            searchTxt = searchTxt + tag.text\n",
    "                \n",
    "return searchTxt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
